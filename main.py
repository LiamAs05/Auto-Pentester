#! /usr/bin/python3
from argparse import ArgumentParser

from src.codes.codes import *  # misc
from src.communicator.communicator import Communicator, TIMEOUT  # network imports
from src.db_manager.SqliteDBManager import SqliteDBManager
from src.db_scraper.db_scraper import DBScraper, Modes  # database imports
from src.io_managers.input_manager import InputManager  # i/o imports
from src.io_managers.output_manager import OutputManager
from src.scan_manager.scan_manager import ScanManager
from src.scan_manager.vulnerability import Vulnerability  # scanner imports
from src.spider.spider import Spider, MAX_PAGES
from src.spider.website import Website, Page  # crawler imports


def main():
    # Input section
    json_path = setup_argparse()
    json = handle_input_json(json_path)  # input parsing

    # Network section
    communicator = initialize_communicator(json)

    # DB section
    DBScraper()
    db_manager = SqliteDBManager()  # creating database connection

    # spider section
    spider = initialize_spider(json, json_path)  # creating crawler instance
    website = get_scraped_website(spider)  # getting Website object created by the spider

    # scans section
    scanner = initialize_scan_manager(website, communicator, db_manager,
                                      json_path, json.get(MODE_JSON_KEY, Modes.NORMAL.value))
    scanner.run()

    # Output section
    handle_output_json(json_path, json, website.get_pages(), scanner.vulnerable_pages)  # output formatting


def get_scraped_website(spider: Spider) -> Website:
    """
    This function returns the pages that the spider found
    @param spider: Website crawler that finds the pages
    @return: dictionary of pages in the website
    @rtype: dict[str, Page]
    """
    spider.logic()
    return spider.get_website()


def handle_input_json(json_path: str) -> dict:
    """
    This function checks that the JSON file is valid
    If a file is invalid, it creates a valid template file in the cwd upon request
    @return: Parsed json file
    @rtype: dict
    """
    if not InputManager.check_for_json(json_path):  # skip if input file is good
        json_path = InputManager.create_json_file(json_path)  # if input file is invalid/not given, ask user to generate
        if not json_path:  # if user didn't generate a template file
            exit(NO_JSON_SUPPLIED)  # exit with error code 1

    return InputManager.parse_input(json_path)


def handle_output_json(json_path: str, json: dict, pages_found: dict[str, Page],
                       vulnerabilities: list[Vulnerability]) -> None:
    """
    This function reports the findings of a program in JSON
    @param json_path: path of the input json file
    @param json: the input json
    @param pages_found: pages that the crawler reached
    @param vulnerabilities:
    @return: None
    """
    OutputManager.extract_info(json_path,
                               json.get(JSON_SCAN_KEY),
                               json.get(JSON_URL_KEY),
                               list(pages_found.keys()),
                               vulnerabilities)


def initialize_scan_manager(website: Website,
                            communicator: Communicator,
                            db_manager: SqliteDBManager,
                            json_path: str,
                            mode: int) -> ScanManager:
    """
    Creating the attack manager
    @param website: website to attack
    @param communicator: communicator instance
    @param db_manager: active database connection
    @param json_path: path to config file with plugins
    @param mode: attack mode
    @return: initialized attack manager
    """
    return ScanManager(website,
                       communicator,
                       db_manager,
                       json_path,
                       mode)


def initialize_communicator(json: dict) -> Communicator:
    """
    Creating the communicator inside a function and returning for clarity purposes
    @param json: input json content
    @return: Communicator object
    """
    return Communicator(json.get(JSON_URL_KEY),
                        json.get("headers"),
                        json.get("cookies"),
                        json.get("auth", tuple()),
                        json.get("use_requests_interface", False),
                        json.get("hidden", True),
                        json.get("timeout", TIMEOUT))


def initialize_spider(json: dict, json_path: str) -> Spider:
    """
    Creating the communicator inside a function and returning for clarity purposes
    @param json_path: location of config.json
    @param json: input json content
    @return: Communicator object
    """
    return Spider(json.get(JSON_URL_KEY),
                  json.get("blacklist"),
                  json.get("cookies"),
                  json.get("auth", tuple()),
                  json_path,
                  json.get("max_pages", MAX_PAGES),
                  json.get("recursive", True))

def setup_argparse() -> str:
    """
    Setting up argument parser
    @return: args
    """
    parser = ArgumentParser(description='Run an automatic penetration test on a website')
    parser.add_argument('config', metavar='config', type=str, help='Json configuration file for the program')
    return parser.parse_args().config

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("Ctrl-C Pressed, Exiting...")
        exit(INTERRUPT)
