#! /usr/bin/python3

import threading

from src.communicator.communicator import Communicator
from src.spider.analyzer.analyzer import Analyzer
from src.spider.website import Website


class Spider:

    def __init__(self, base_url: str, blacklist: set[str], cookies: dict, auth: tuple[str, str]):
        self.base_url = base_url
        self.blacklist = blacklist
        self.cookies = cookies
        self.auth = auth

        self._communicator = None
        self._website = Website(self.base_url, self.cookies)

        self._current_url = self.base_url
        self._current_page_plain_text = None

        self._threads = []

        self._pages = set()
        self._parsed_routes = set()

        # route: parent route
        self._route_to_parse = dict()

        self._pages_lock = threading.Lock()
        self._route_to_parse_lock = threading.Lock()

        self._route_to_parse[self.base_url] = self.base_url

        self._communicator = Communicator(self.base_url,
                                          cookies=self.cookies,
                                          auth=self.auth,
                                          use_requests_interface=True)

    def logic(self) -> None:
        """
        Function map the eintr website

        flow:

        while there is a route to parse or threads running (because they give route to parse)
            if there is no route to parse:
                wait for the thread results


            get a route to parse from the list of route to parse
            get the page (web url) from the communicator

            pass it to the analyzer (the analyzer will put the new routes in the list)
            add the thread to thread list

        register put the pages in the website
        """

        while self._route_to_parse or self._threads:

            self._route_to_parse_lock.acquire()

            if not self._route_to_parse:
                self._route_to_parse_lock.release()

                self.wait_to_threads()
                continue

            temp_route, parent_route = self._route_to_parse.popitem()

            self._route_to_parse_lock.release()

            if temp_route in self._parsed_routes:
                continue

            self._parsed_routes.add(temp_route)

            self._current_url = self.base_url + temp_route

            self._current_page_plain_text = self._communicator.simple_get(self._current_url).text

            t = threading.Thread(
                target=Analyzer.parse_page,

                args=(
                    self._current_page_plain_text,
                    self._current_url,
                    parent_route,

                    self._pages,
                    self._route_to_parse,
                    self.blacklist,

                    self._pages_lock,
                    self._route_to_parse_lock,
                    )
                )

            self._threads.append(t)

        self._register_pages()

    def get_website(self) -> Website:
        return self._website

    def _register_pages(self) -> None:
        """
        function register all the pages to the website
        """
        for page in self._pages:
            self._website.add_page(page)

    def wait_to_threads(self) -> None:
        """
        Function wait till all the threads have finished, and then clear the thread list
        """
        for thread in self._threads:
            thread.join()

        self._threads.clear()
