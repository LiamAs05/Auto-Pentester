#! /usr/bin/python3

import threading

from src.communicator.communicator import Communicator
from src.analyzer.analyzer import Analyzer

from src.spider.plugins_manager import PluginManager
from src.spider.website import Website

from src.classificator.classificator import Classificator

MAX_PAGES = 100


class Spider:

    def __init__(
            self, base_url: str,
            blacklist: set[str],
            cookies: dict,
            auth: tuple[str, str],
            max_pages: int = MAX_PAGES,
            recursive: bool = True
    ):
        self.base_url = base_url
        self.blacklist = blacklist
        self.cookies = cookies
        self.auth = auth

        self.max_pages = max_pages
        self.recursive = recursive

        self._communicator = None
        self._website = Website(self.base_url, self.cookies)

        self._current_url = self.base_url
        self._current_page_plain_text = None

        self._threads = []

        self._temp_route = None
        self._parent_route = None

        self._pages = set()
        self._parsed_routes = set()

        # route: parent route
        self._route_to_parse = dict()

        self._pages_lock = threading.Lock()
        self._route_to_parse_lock = threading.Lock()

        self._route_to_parse[self.base_url] = self.base_url

        self._plugin_elements = PluginManager.get_plugins()

        self._communicator = Communicator(self.base_url,
                                          cookies=self.cookies,
                                          auth=self.auth,
                                          use_requests_interface=True)

        self._is_session = False
        self._need_auth = False

    def logic(self) -> None:
        """
        Function map the eintr website

        flow:

        while there is a route to parse or threads running (because they give route to parse)
            if there is no route to parse:
                wait for the thread results


            get a route to parse from the list of route to parse
            get the page (web url) from the communicator

            pass it to the analyzer (the analyzer will put the new routes in the list)
            add the thread to thread list

        register put the pages in the website
        """

        if not self.recursive:
            response = self._communicator.simple_get(self.base_url)
            self._create_thread(response)

        while (self._route_to_parse or self._threads) and self.max_pages and self.recursive:

            self.max_pages -= 1

            self._route_to_parse_lock.acquire()
            try:
                self._temp_route, self._parent_route = self._route_to_parse.popitem()
                self._parsed_routes.add(self._temp_route)

            except KeyError:
                self.wait_to_threads()
                continue

            finally:
                self._route_to_parse_lock.release()

            self._current_url = self.base_url + self._temp_route

            response = self._communicator.simple_get(self._current_url, self.cookies)

            if (response and not response.ok) or not response:
                continue

            is_login_page, action, params = Classificator.is_login_page(response, self.auth)

            if is_login_page:
                self._current_url = self.base_url + action
                response = self._communicator.post(
                    self._current_url,
                    data=params,
                    params=params,
                    auth=self.auth,
                    cookies=self.cookies
                )

                if (response and not response.ok) or not response:
                    continue
            self._create_thread(response)

        self.wait_to_threads()
        self._register_pages()

    def _create_thread(self, response):
        t = threading.Thread(
            target=Analyzer.parse_page,

            args=(
                response,
                self.base_url,
                self._temp_route,
                self._parent_route,

                self._plugin_elements,

                self._pages,
                self._route_to_parse,
                self.blacklist,

                self._pages_lock,
                self._route_to_parse_lock,

                self.auth,
                self._is_session,
                self._need_auth,
            )
        )

        self._threads.append(t)

    def get_website(self) -> Website:
        return self._website

    def _register_pages(self) -> None:
        """
        function register all the pages to the website
        """
        for page in self._pages:
            self._website.add_page(page)

    def wait_to_threads(self) -> None:
        """
        Function wait till all the threads have finished, and then clear the thread list
        """
        for thread in self._threads:
            thread.join()

        self._threads.clear()
