#! /usr/bin/python3

import threading

from analyzer.analyzer import Analyzer
from website import Website

# todo Communicator


class Spider:

    def __init__(self, base_url: str, blacklist: set[str], cookies: dict, auth: tuple[str, str]):
        self.base_url = base_url
        self.blacklist = blacklist
        self.cookies = cookies
        self.auth = auth

        self._communicator = None
        self._website = Website(self.base_url, self.cookies)

        self._current_url = self.base_url
        self._current_page_plain_text = None

        self._threads = []

        self._pages = set()
        self._parsed_routes = set()

        # route: parent route
        self._route_to_parse = dict()

        self._pages_lock = threading.Lock()
        self._parsed_routes_lock = threading.Lock()
        self._route_to_parse_lock = threading.Lock()

        self._route_to_parse[self.base_url] = self.base_url

        # todo Register communicator auth and cookies

    def logic(self) -> None:
        """
        Function map the eintr website

        flow:

        while there is a route to parse or threads running (because they give route to parse)
            if there is no route to parse:
                wait for the thread results


            get a route to parse from the list of route to parse
            get the page (web url) from the communicator

            pass it to the analyzer (the analyzer will put the new routes in the list)
            add the thread to thread list

        register put the pages in the website
        """

        while self._route_to_parse or self._threads:

            self._route_to_parse_lock.acquire()

            if not self._route_to_parse:
                self._route_to_parse_lock.release()

                self.wait_to_threads()
                continue

            temp_url, parent_route = self._route_to_parse.popitem()

            self._route_to_parse_lock.release()

            self._current_url = self.base_url + temp_url

            self._current_page_plain_text = self._communicator.simple_get(self._current_url)

            if not self._current_page_plain_text:
                continue

            t = threading.Thread(
                target=Analyzer.parse_page,

                args=(
                    self._current_page_plain_text,
                    self._current_url,
                    parent_route,

                    self._pages,
                    self._route_to_parse,
                    self._parsed_routes,
                    self.blacklist,

                    self._pages_lock,
                    self._route_to_parse_lock,
                    self._parsed_routes_lock,
                    )
                )

            self._threads.append(t)

        self._register_pages()

    def get_website(self) -> Website:
        return self._website

    def _register_pages(self) -> None:
        """
        function register all the pages to the website
        """
        for page in self._pages:
            self._website.add_page(page)

    def wait_to_threads(self) -> None:
        """
        Function wait till all the threads have finished, and then clear the thread list
        """
        for thread in self._threads:
            thread.join()

        self._threads.clear()
